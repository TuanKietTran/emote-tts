\documentclass[12pt,a4paper]{article}
\usepackage[english]{babel}
\usepackage{titlesec}

% \titleformat{\chapter} % command [display] % shape {\bfseries\huge} % format
%   {Chapter \thechapter} % label {0pt} % sep {} % before-code


\usepackage[T5]{fontenc}
\usepackage{mathptmx}[ptm]
\usepackage{a4wide, amssymb, epsfig, latexsym, array, hhline, fancyhdr}
\usepackage[normalem]{ulem}
%\usepackage{soul}
\usepackage{float}
\usepackage[makeroom]{cancel}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{multicol, longtable, amscd}
\usepackage{diagbox}%Make diagonal lines in tables
\usepackage{booktabs}
\usepackage{alltt}
\usepackage[framemethod=tikz]{mdframed}% For highlighting paragraph backgrounds
\usepackage{indentfirst}
\usepackage{caption,subcaption}
\usepackage{svg}
\graphicspath{ {figures/} }
\usepackage{lastpage}
\usepackage[lined,boxed,commentsnumbered]{algorithm2e}
\usepackage{enumerate}
\usepackage{color}
\usepackage{graphicx}% Standard graphics package
\graphicspath{ {figures/} }
\usepackage{array}
\usepackage{tabularx, caption}
\usepackage{tabularray}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{rotating}
\usepackage{graphics}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{epsfig}
\usepackage{tikz}
\usepackage[numbers]{natbib}
\usepackage{subcaption}
\usepackage{dirtree}

\usetikzlibrary{arrows, snakes, backgrounds, calc}
\usepackage[unicode]{hyperref}
\hypersetup{urlcolor=blue,linkcolor=black,citecolor=black,colorlinks=true} 

\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\usepackage{listings}
\lstdefinestyle{mystyle}{ backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen}, keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray}, stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize, breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false, showtabs=false,                  
    tabsize=2 }
\lstset{style=mystyle}



\def\thesislayout{	% A4: 210 × 297
	\geometry{ a4paper, total={160mm,240mm},  % fix over page
		left=30mm, top=30mm, } }
\thesislayout

%\usepackage{fancyhdr}
\setlength{\headheight}{40pt}
\pagestyle{fancy}
\fancyhead{} % clear all header fields
\fancyhead[L]{
 \begin{tabular}{rl}
    \begin{picture}(25,15)(0,0) \put(0,-8){\includegraphics[width=10mm,
    height=10mm]{Images/hcmut.png}}
    %\put(0,-8){\epsfig{width=10mm,figure=hcmut.eps}}
   \end{picture}&
	%\includegraphics[width=8mm, height=8mm]{hcmut.png} & %
	\begin{tabular}{l}
        \textbf{ Ho Chi Minh City University of Technology } \\
        \textbf{ Faculty of Computer Science and Engineering }
	\end{tabular} 	
 \end{tabular}
} \fancyhead[R]{
	\begin{tabular}{l}
		\tiny \bf \\
		\tiny \bf \end{tabular}  } \fancyfoot{} % clear all footer fields
\fancyfoot[L]{\scriptsize Modern Speech Processing (CO5257) - Academic year 2024 - 2025}
\fancyfoot[R]{\scriptsize  Page {\thepage}/\pageref{LastPage}}
\renewcommand{\headrulewidth}{0.3pt}
\renewcommand{\footrulewidth}{0.3pt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Tạo một môi trường mới cho các bảng đặc tả UC, giúp định dạng kiểu
\newenvironment{usecase_table}[1][Test]
{
\begin{table}[H]
% Left-Right Table padding
    \setlength{\tabcolsep}{6pt}
    \renewcommand{\arraystretch}{1.5}
    % \begin{tabularx}{\textwidth}{bs}
    \def\savedcaption{\caption{#1}}%
    \begin{tabular}{|>{\bfseries} p{0.2\linewidth}|p{0.7\linewidth}|}

} {
    \end{tabular}
    \savedcaption
\end{table}
}

\newenvironment{usecase_enum}
{
    \begin{enumerate*}[itemjoin={\newline}]
} {
    \end{enumerate*}
}

\makeatletter
\newenvironment{acknowledgments}{
	\small
	\begin{center}
	  {\bfseries Acknowledgments\vspace{-.5em}\vspace{\z@}}
	\end{center}
	\quotation
  }{}
\makeatother

% Declaration
\makeatletter
\newenvironment{declaration}{
	\small
	\begin{center}
	  {\bfseries Declaration\vspace{-.5em}\vspace{\z@}}
	\end{center}
	\quotation
  }{}
\makeatother

\makeatletter
\newenvironment{abstr}{
        \small
        \begin{center}
	{\bfseries Abstract \vspace{-.5em}\vspace{\z@}}
        \end{center}
        \quotation
    }{}
\makeatother

\makeatletter
\newenvironment{abstrsss}{
        \small
        \begin{center}
	{\bfseries Abstractss \vspace{-.5em}\vspace{\z@}}
        \end{center}
        \quotation
    }{}
\makeatother
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{3}
\makeatletter
\newcounter {subsubsubsection}[subsubsection]
\renewcommand\thesubsubsubsection{\thesubsubsection .\@alph\c@subsubsubsection}
\newcommand\subsubsubsection{\@startsection{subsubsubsection}{4}{\z@}%
                                     {-3.25ex\@plus -1ex \@minus -.2ex}%
                                     {1.5ex \@plus .2ex}%
                                     {\normalfont\normalsize\bfseries}}
\newcommand*\l@subsubsubsection{\@dottedtocline{3}{10.0em}{4.1em}}
\newcommand*{\subsubsubsectionmark}[1]{}
\makeatother



\everymath{\color{black}}%make in-line maths symbols blue to read/check easily

\sloppy
\captionsetup[figure]{labelfont={small,bf},textfont={small,it},belowskip=-1pt,aboveskip=-9pt}
%space removed between caption, figure, and text
\captionsetup[table]{labelfont={small,bf},textfont={small,it},belowskip=-1pt,aboveskip=7pt}
\setlength{\floatsep}{5pt plus 2pt minus 2pt}
\setlength{\textfloatsep}{5pt plus 2pt minus 2pt}
\setlength{\intextsep}{10pt plus 2pt minus 2pt}


% Declare a variable named Proc using \newcommand

\newcommand{\Uni}{Ho Chi Minh University - Vietnam National Unversity, Ho Chi Minh City}

\renewcommand{\labelitemi}{\normalfont\bfseries\textendash}
\renewcommand{\labelitemii}{\textbullet}
\renewcommand*\baselinestretch{1.5}\selectfont


\thesislayout

\begin{document}

\begin{titlepage}
    \begin{tikzpicture}[remember picture, overlay]
        \draw[line width = 4pt] ($(current page.north west) + (1.0in,-0.5in)$)
        rectangle ($(current page.south east) + (-0.4in,0.5in)$);
        \draw[line width=1.5pt]
        ($ (current page.north west) + (1.05in,-0.55in) $) rectangle ($ (current
        page.south east) + (-0.45in,0.55in) $);
    \end{tikzpicture}

    \begin{center}
        \large \textbf{VIETNAM NATIONAL UNIVERSITY, HO CHI MINH CITY} \\
        \large \textbf{HO CHI MINH UNIVERSITY OF TECHNOLOGY} \\
        \large \textbf{FACULTY OF COMPUTER SCIENCE AND ENGINEERING}
    \end{center}

    \begin{figure}[h!]
        \begin{center}
            \includegraphics[width=5cm]{Images/hcmut.png}
        \end{center}
    \end{figure}

    \begin{center}
        \begin{tabular}{c}
        \multicolumn{1}{l}{\textbf{{\Large Modern Speech Processing
        (CO5257)}}}\\
        ~~\\
        \hline
        \\
        \multicolumn{1}{l}{\textbf{{\Large Assignment Report}}}\\
        \\
        \textbf{{\Large Enhancing Vocoder Designs }}\\
        \textbf{{\Large with Emotion Embeddings and Emotional Cues}}\\
        \\
        \hline
        \end{tabular}
        \end{center}

    \vspace{1cm}
    \begin{table}[H]
        \begin{tabular}{rrl}
        \hspace{5 cm} & \textbf{Mentor}: & Nguyễn Đức Dũng\\
        
        & \textbf{Student}: & Trần Hà Tuấn Kiệt -- 2011493 \\
        
        \end{tabular}
        \end{table}
    \vspace{1cm}

    \begin{center}
        {\large Ho Chi Minh City, \the\month/\the\year}
    \end{center}
\end{titlepage}

\newpage

% Revert title name back to English
\renewcommand{\contentsname}{Table of Contents}
\renewcommand{\listfigurename}{List of Figures}
\renewcommand{\listtablename}{List of Tables}
\renewcommand{\bibname}{References}
\renewcommand{\figurename}{Figure}

\tableofcontents
\newpage

%\thispagestyle{empty} \renewcommand\thechapter{Chapter \arabic{chapter}}

\section*{Abstract}
This article explores the integration of emotion embeddings and emotional cues
into vocoder architectures to enhance expressiveness in speech synthesis. Modern
vocoders, while capable of producing high-quality audio, often fail to
effectively capture the nuanced prosody and variability required for emotionally
rich speech. By conditioning vocoders with emotion-specific embeddings and
leveraging emotional cues such as pitch, rhythm, and intensity, this study aims
to bridge the gap between technical accuracy and human-like expressiveness.
Moreover, the study proposes a universal emotion-aware conditioning framework
applicable to neural, statistical, and hybrid vocoder designs. Through a
combination of theoretical exploration and empirical validation, the methodology
demonstrates improvements in emotional fidelity and naturalness across
synthesized speech outputs.
\newpage
\section{Introduction}

In recent years, synthetic speech technology has seen a marked expansion within
human-computer interaction. This trend reflects the inherent complexity of human
speech, which encodes not only linguistic content but also para-linguistic and
non-linguistic cues. Linguistic information can be derived directly from written
text or contextual inferences, whereas para-linguistic features are deliberately
introduced by the speaker to enhance or modify the message. By contrast,
non-linguistic aspects---such as emotional state---are often beyond the
speaker’s voluntary control, presenting additional challenges in achieving truly
expressive synthesized speech \cite{an2021emotional}. These complexities have
motivated extensive research in text-to-speech (TTS) synthesis aiming to
generate stylish, expressive, or emotional speech \cite{nose2007style,
henter2017principles, lorenzotrueba2018investigating, wang2018style,
skerry2018towards, wu2018feature, wu2018rapid, liu2020multi}. Ultimately,
bridging these complexities is crucial for creating speech synthesis that feels
natural and truly conveys the richness of human speech.

To tackle these challenges and more accurately model the multifaceted nature of
human speech, researchers have turned to advanced neural network architectures.
\emph{Neural vocoders} represent a cutting-edge technology in speech synthesis,
specializing in transforming intermediate acoustic representations, such as
spectrograms, into lifelike audio waveforms \cite{oord2016wavenet,
jang2021univnet, siuzdak2022vocos}. Renowned for their capability to produce
high-fidelity, natural-sounding speech, these models have become a pivotal
component of contemporary speech synthesis frameworks
\cite{albadawy2021vocbench, zarazaga2022neural}. Moreover, emotion embeddings
have emerged as a key strategy to capture and encode subtle emotional
cues---including intonation, prosody, and timbre---in a learned representation.
When integrated into modern TTS pipelines, such embeddings enrich the expressive
range of synthesized speech, making it more engaging and human-like
\cite{lei2022msemotts}. However, accurately modeling the nuances of emotion
remains an ongoing challenge, driven by the inherent complexity of emotional
expression and the diverse contexts in which it
appears\cite{raptis2014expressive}. This paper aims to integrate emotion
embeddings directly into the waveform generation process through a novel neural
vocoder architecture. By leveraging these representations, the system aspires to
produce speech that is both high-fidelity and emotionally expressive, unlocking
applications in empathetic virtual agents, personalized audiobooks, and
emotion-driven interfaces that enhance user engagement and interactivity.

The current state of research in emotional speech synthesis and text-to-speech
(TTS) systems highlights the use of specialized datasets and intermediate
modules, such as prosody-driven conditioning, to achieve expressive outputs.
Frameworks like Tacotron \cite{wang2017tacotron}, paired with neural vocoders
such as WaveNet \cite{oord2016wavenet} and HiFi-GAN \cite{kong2020hifi}, have
become foundational in this domain. Many systems incorporate emotion or style
tokens \cite{wang2018style}, which allow modulation of the synthesized speech to
reflect various emotional states. While these approaches have successfully
synthesized clear emotional expressions, challenges persist in generating
nuanced and diverse emotions, especially in handling complex states or
transitions. Additionally, ensuring robustness remains an issue, as small
variations in embeddings can lead to significant changes in the quality or
nature of the output \cite{zhang2021deep}. Emotional Voice Conversion (EVC) and
our project, "Enhancing Vocoder with Emotion Embeddings \& Cues," share some
conceptual similarities but differ in scope and focus. EVC is a broader approach
that seeks to transform a neutral or source utterance into a target emotional
style without altering speaker identity, often involving a comprehensive
pipeline that includes acoustic feature extraction, prosody modeling, and
vocoder synthesis. These systems frequently use parallel data or disentanglement
techniques to separate speaker traits from emotional features
\cite{zhou2020transforming}. By contrast, our work focuses specifically on the
vocoder stage, where we integrate learned emotional embeddings or cues directly
into the waveform generation process. This enables finer control over
intonation, timbre, and microprosody, allowing for more precise and natural
emotional rendering. Unlike EVC, which modifies the entire pipeline to achieve
emotional transformation, our method emphasizes refining the vocoder to achieve
stable, contextually appropriate emotional outputs. This targeted approach
enhances the vocoder’s ability to express subtle emotional nuances, providing
greater flexibility and control over the synthesized speech’s emotional quality
\cite{kim2021conditional}.

\newpage
\section {Methodology}


\newpage
\section {Experiments}

\newpage

\section{Evaluations}

\newpage
\section{Conclusion}

\newpage
\nocite{*}
\bibliographystyle{ieeetr}

\bibliography{refs}

\end{document}